{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.nn import Sequential as seq\n",
    "from torch.nn import Conv1d as c1d\n",
    "from torch.nn import Linear as l_n\n",
    "from torch.nn import ReLU as rel\n",
    "from torch.nn import Dropout as drop\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterConvolutionNetwork(nn.Module):                                       # Class for Character Convolution Network (CCN) \n",
    "    def __init__(self, n_classes=4, input_length=1014, input_dim=68):\n",
    "        self.ker_siz=[7,7,3,3,3,3]\n",
    "        super(CharacterConvolutionNetwork, self).__init__()\n",
    "        self.conv1 = seq(c1d(input_dim, 256, kernel_size=self.ker_siz[0]), rel(),\n",
    "                                   nn.MaxPool1d(3))\n",
    "        self.conv2 = seq(c1d(256, 256, kernel_size=self.ker_siz[1], padding=0), rel(),\n",
    "                                   nn.MaxPool1d(3))\n",
    "        self.conv3 = seq(c1d(256, 256, kernel_size=self.ker_siz[2], padding=0), rel())\n",
    "        self.conv4 = seq(c1d(256, 256, kernel_size=self.ker_siz[3], padding=0), rel())\n",
    "        self.conv5 = seq(c1d(256, 256, kernel_size=self.ker_siz[4], padding=0), rel())\n",
    "        self.conv6 = seq(c1d(256, 256, kernel_size=self.ker_siz[5], padding=0), rel(),\n",
    "                                   nn.MaxPool1d(3))\n",
    "\n",
    "        dimension = int((input_length - 96) / 27 * 256)\n",
    "        self.fc1 = seq(l_n(dimension, 1024), drop(0.5))\n",
    "        self.fc2 = seq(l_n(1024, 1024), drop(0.5))\n",
    "        self.fc3 = l_n(1024, n_classes)\n",
    "        mn = 0.0\n",
    "        std_dev = 0.05\n",
    "        self._weights(mean=mn, std=std_dev)\n",
    "\n",
    "    def _weights(self, mean=0, std=0.05):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, c1d) or isinstance(module, l_n):\n",
    "                module.weight.data.normal_(mean, std)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        inp = inp.transpose(1, 2)\n",
    "        y = self.conv1(inp)\n",
    "        y = self.conv2(y)\n",
    "        y = self.conv3(y)\n",
    "        y = self.conv4(y)\n",
    "        y = self.conv5(y)\n",
    "        y = self.conv6(y)\n",
    "        y = y.view(y.size(0), -1)\n",
    "        y = self.fc1(y)\n",
    "        y = self.fc2(y)\n",
    "        y = self.fc3(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharacterConvolutionNetwork(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv1d(68, 256, kernel_size=(7,), stride=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv1d(256, 256, kernel_size=(7,), stride=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv5): Sequential(\n",
      "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv6): Sequential(\n",
      "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=8704, out_features=1024, bias=True)\n",
      "    (1): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (1): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (fc3): Linear(in_features=1024, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "characterConvolutionNetwork = CharacterConvolutionNetwork(4)\n",
    "print(characterConvolutionNetwork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      class                                              title  \\\n",
      "0         3                  Fears for T N pension after talks   \n",
      "1         4  The Race is On: Second Private Team Sets Launc...   \n",
      "2         4      Ky. Company Wins Grant to Study Peptides (AP)   \n",
      "3         4      Prediction Unit Helps Forecast Wildfires (AP)   \n",
      "4         4        Calif. Aims to Limit Farm-Related Smog (AP)   \n",
      "...     ...                                                ...   \n",
      "7595      1                                   Around the world   \n",
      "7596      2                        Void is filled with Clement   \n",
      "7597      2                             Martinez leaves bitter   \n",
      "7598      3  5 of arthritis patients in Singapore take Bext...   \n",
      "7599      3                             EBay gets into rentals   \n",
      "\n",
      "                                                   desc  \n",
      "0     Unions representing workers at Turner   Newall...  \n",
      "1     SPACE.com - TORONTO, Canada -- A second\\team o...  \n",
      "2     AP - A company founded by a chemistry research...  \n",
      "3     AP - It's barely dawn when Mike Fitzpatrick st...  \n",
      "4     AP - Southern California's smog-fighting agenc...  \n",
      "...                                                 ...  \n",
      "7595  Ukrainian presidential candidate Viktor Yushch...  \n",
      "7596  With the supply of attractive pitching options...  \n",
      "7597  Like Roger Clemens did almost exactly eight ye...  \n",
      "7598  SINGAPORE : Doctors in the United States have ...  \n",
      "7599  EBay plans to buy the apartment and home renta...  \n",
      "\n",
      "[7600 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(r'./dataset/train.csv')\n",
    "train_df=pd.DataFrame(data,columns=[\"class\",\"title\",\"desc\"])\n",
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        class                                              title  \\\n",
      "0           3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
      "1           3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
      "2           3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
      "3           3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
      "4           3  Oil prices soar to all-time record, posing new...   \n",
      "...       ...                                                ...   \n",
      "119995      1  Pakistan's Musharraf Says Won't Quit as Army C...   \n",
      "119996      2                  Renteria signing a top-shelf deal   \n",
      "119997      2                    Saban not going to Dolphins yet   \n",
      "119998      2                                  Today's NFL games   \n",
      "119999      2                       Nets get Carter from Raptors   \n",
      "\n",
      "                                                     desc  \n",
      "0       Reuters - Short-sellers, Wall Street's dwindli...  \n",
      "1       Reuters - Private investment firm Carlyle Grou...  \n",
      "2       Reuters - Soaring crude prices plus worries\\ab...  \n",
      "3       Reuters - Authorities have halted oil export\\f...  \n",
      "4       AFP - Tearaway world oil prices, toppling reco...  \n",
      "...                                                   ...  \n",
      "119995   KARACHI (Reuters) - Pakistani President Perve...  \n",
      "119996  Red Sox general manager Theo Epstein acknowled...  \n",
      "119997  The Miami Dolphins will put their courtship of...  \n",
      "119998  PITTSBURGH at NY GIANTS Time: 1:30 p.m. Line: ...  \n",
      "119999  INDIANAPOLIS -- All-Star Vince Carter was trad...  \n",
      "\n",
      "[120000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(r'./dataset/test.csv')\n",
    "test_df=pd.DataFrame(data,columns=[\"class\",\"title\",\"desc\"])\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self,df, max_length=1014):\n",
    "#         self.data_path = data_path\n",
    "        strr=\"\"\"abcdefghijklmnopqrstuvwxyz0123456789,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\"\"\"\n",
    "        self.vocabulary = list(strr)\n",
    "\n",
    "        self.identity_mat = np.identity(len(self.vocabulary))\n",
    "        texts, labels = [], []\n",
    "        \n",
    "        self.labels = [int(i)-1 for i in df['class'].values]\n",
    "        self.num_classes = len(set(self.labels))\n",
    "        self.length = len(self.labels)\n",
    "        self.texts = df['desc'].values\n",
    "        self.max_length = max_length\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        raw_text = self.texts[index]\n",
    "        isi_text = self.texts[index]\n",
    "        vocabb= self.vocabulary\n",
    "        data = np.array([self.identity_mat[self.vocabulary.index(i)] for i in list(raw_text) if i in vocabb], dtype=np.float32)\n",
    "\n",
    "        if len(data) == 0:\n",
    "            data = np.zeros((self.max_length, len(self.vocabulary)), dtype=np.float32)\n",
    "        \n",
    "        \n",
    "        elif self.max_length > len(data) > 0 :\n",
    "            data = np.concatenate((data, np.zeros((-(len(data) - self.max_length), len(self.vocabulary)), dtype=np.float32)))\n",
    "        \n",
    "        elif  self.max_length < len(data):\n",
    "            data = data[:self.max_length]\n",
    "        \n",
    "        label = self.labels[index]\n",
    "        \n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset=TextDataset(train_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c097115f3f593a9e698ec3fb56a57288f7b940348a514484af70c039fb74828"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
